{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Introduction\n",
    "## Tabular Q-Learning\n",
    "(by: [Nicolaj Stache](mailto:Nicolaj.Stache@hs-heilbronn.de), and [Pascal Graf](mailto:pascal.graf@hs-heilbronn.de), both: Heilbronn University, Germany, June 2022) \n",
    "\n",
    "In this notebook we look at a simple reinforcement learning problem and the tabular Q-Learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Table of Contents:\n",
    "### 1. [Imports](#imports)\n",
    "\n",
    "### 2. [Environment](#environment)\n",
    "\n",
    "### 3. [Training](#training)\n",
    "\n",
    "### 4. [Evaluation](#evaluation)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment <a class=\"anchor\" id=\"environment\"></a>\n",
    "The environment we're going to solve is called \"Grid World\". The respective Python file is stored in a folder along with this notebook. The task is to reach the terminal state that yields a positive reward in a grid with arbitrary size. Every other step in the environment leads to a slight negative reward. There are also obstacles randomly distributed over the environment and a terminal field to avoid which yields a negative reward.\n",
    "<hr>\n",
    "\n",
    "**TO DO:** Take a look into the grid_world file and try to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.grid_world import Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new random Grid World and explore the environment\n",
    "Initialize the grid environment, then print its structure as well as the the rewards that are obtained reaching each state.\n",
    "<hr>\n",
    "\n",
    "**TO DO:** Make sure the target field is reachable. Each function call will create a new random grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid World:\n",
      "------------------------------\n",
      "     |  x  |     |     |     |\n",
      "------------------------------\n",
      "     |     |     |     |     |\n",
      "------------------------------\n",
      "     |  t  |     |  x  |  a  |\n",
      "------------------------------\n",
      "  x  |     |     |     |  s  |\n",
      "------------------------------\n",
      "\n",
      "Rewards:\n",
      "------------------------------\n",
      "-0.10| 0.00|-0.10|-0.10|-0.10|\n",
      "------------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|-0.10|\n",
      "------------------------------\n",
      "-0.10| 1.00|-0.10| 0.00|-1.00|\n",
      "------------------------------\n",
      " 0.00|-0.10|-0.10|-0.10|-0.10|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new Grid World\n",
    "grid = Grid(5, 4, step_reward=-0.1, obstacles=3)\n",
    "# Print grid structure\n",
    "print(\"Grid World:\")\n",
    "grid.print_grid()\n",
    "\n",
    "print(\"Rewards:\")\n",
    "grid.print_grid_rewards()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training <a class=\"anchor\" id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameters\n",
    "The success of the reinforcement learning algorithm heavily depends of the choice of parameters. Among these are the learning rate $\\alpha$, the discount factor $\\gamma$ and the exploration parameters. \n",
    "<hr>\n",
    "\n",
    "**TO DO:** After successfully training the algorithm with the default parameters, try modifying `EPSILON`, `EPSILON_DECAY`, `GAMMA` and `ALPHA` to get a feel for their effects on the learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training episodes\n",
    "EPISODES = 10000\n",
    "# Discount Factor\n",
    "GAMMA = 0.9\n",
    "# Learning Rate\n",
    "ALPHA = 0.05\n",
    "# Epsilon\n",
    "EPSILON = 1\n",
    "# Decay of random actions\n",
    "EPSILON_DECAY = 0.95\n",
    "# Action space (Up, Down, Left, Right)\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning Algorithm\n",
    "Q-Learning is an online, off-policy, non-model-based, bootstrapping reinforcement learning algorithm. We will use a modified implementation taken from [here](https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python) in attempt to solve the Grid World environment. Underneath you can see the pseudo code for tabular Q-Learning.\n",
    "\n",
    "\n",
    "#### Q-Learning Pseudo Code\n",
    "<hr>\n",
    "\n",
    "- Initialize:\n",
    "    - Step Size $\\alpha \\in (0,1]$ \n",
    "    - $Q(s,a)$ dictionary for all $s\\in S, a \\in A$.\n",
    "    - $\\epsilon > 0$\n",
    "- Loop for each episode:\n",
    "    1. Choose $A$ from $S$ using an $\\epsilon$-greedy policy.\n",
    "    2. Take action $A$, observe $R, S'$.\n",
    "    3. $Q(S,A)\\leftarrow Q(S,A) + \\alpha [R+\\gamma max_a Q(S', a)-Q(S,A)]$\n",
    "    4. $S\\leftarrow S'$\n",
    "    \n",
    "    until $S$ is terminal\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellaneous functions\n",
    "\n",
    "In order to perform and evaluate the training we need some helper functions. \n",
    "\n",
    "The **`max_dict`** function accepts a dictionary as parameter, loops through the dictionary and returns the maximum value as well as its key.\n",
    "\n",
    "The **`act_epsilon_greedy`** function selects an action from a dictionary according to the epsilon-greedy algorithm. This means, in $\\epsilon$ percent of the cases it returns a random action, otherwise the action is chosen greedily according to a action-value dictionary.\n",
    "<hr>\n",
    "\n",
    "\n",
    "**TO DO:** \n",
    "1. Complete the **`max_dict`** function to return the maximum value and its respective key from a dictionary.\n",
    "\n",
    "2. Complete the **`act_epsilon_greedy`** function to select a random action from `ALL_POSSIBLE_ACTIONS` if a random value is smaller or equal to $\\epsilon$. Otherwise act greedily with respect to $Q(s,a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    '''Returns the argmax (key) and max (value) from a dictionary.'''\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    return max_key, max_val\n",
    "\n",
    "def act_epsilon_greedy(Qs, eps=0.1):\n",
    "    '''Selects an epsilon greedy action given the action-values for a state and epsilon.'''\n",
    "    if np.random.random() <= eps:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    a, _ = max_dict(Qs)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "<hr>\n",
    "\n",
    "**TO DO:** Complete the following code to correspond to the pseude code above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Epsilon: 1\n",
      "Episode: 1000, Epsilon: 0.5987369392383786\n",
      "Episode: 2000, Epsilon: 0.35848592240854177\n",
      "Episode: 3000, Epsilon: 0.2146387639429372\n",
      "Episode: 4000, Epsilon: 0.1285121565651031\n",
      "Episode: 5000, Epsilon: 0.07694497527671314\n",
      "Episode: 6000, Epsilon: 0.04606979898695193\n",
      "Episode: 7000, Epsilon: 0.027583690436774957\n",
      "Episode: 8000, Epsilon: 0.016515374385013576\n",
      "Episode: 9000, Epsilon: 0.009888364709658948\n"
     ]
    }
   ],
   "source": [
    "# Set initial exploration\n",
    "eps = EPSILON\n",
    "\n",
    "# Initialize an empty dictionary for the action-value function Q(s,a)\n",
    "Q = {}\n",
    "# Initialize an empty dictionary for the number of times action a has been chosen in state s.\n",
    "action_visits = {}\n",
    "# Initialize an empty dictionary for the number of times state s has been visited.\n",
    "state_visits = {}\n",
    "\n",
    "# For each state corresponding to each field in the environment, create a new dictionary inside the dictionaries.\n",
    "for row in range(grid.height):\n",
    "    for col in range(grid.width):\n",
    "        Q[(row, col)] = {}\n",
    "        action_visits[(row, col)] = {}\n",
    "        state_visits[(row, col)] = 1\n",
    "        # For each action in each state create a new entry in the dictonary setting its estimated value to 0 and its visits to 1.\n",
    "        for a in ALL_POSSIBLE_ACTIONS:\n",
    "            Q[(row, col)][a] = 0\n",
    "            action_visits[(row, col)][a] = 1\n",
    "            \n",
    "# Keep track of the maximum value changes during each episode so we can plot a learning curve after the training       \n",
    "deltas = []\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "# Play EPISODES number of episodes in the environment while learning after each step.\n",
    "for e in range(EPISODES):\n",
    "    # Every 1000 steps print the current episode number and epsilon\n",
    "    if e % 1000 == 0:\n",
    "        print(\"Episode: {}, Epsilon: {}\".format(e, eps))\n",
    "        \n",
    "    # Decrease epsilon every 100 episodes to approach a more deterministic policy.\n",
    "    if e % 100 == 0 and eps>0:\n",
    "        eps *= EPSILON_DECAY\n",
    "\n",
    "    # Set the starting state\n",
    "    grid.reset()\n",
    "    s = grid.get_current_state()\n",
    "\n",
    "    biggest_change = 0\n",
    "    while not grid.is_state_terminal():\n",
    "        # Choose an action epsilon-greedily.\n",
    "        a = act_epsilon_greedy(Q[s], eps=eps)\n",
    "        r = grid.move(a)\n",
    "        next_s = grid.get_current_state()\n",
    "        \n",
    "        # Update the state and action visits number.\n",
    "        state_visits[s] += 1\n",
    "        action_visits[s][a] += 1\n",
    "\n",
    "        # Update Q(s,a)\n",
    "        old_qsa = Q[s][a]\n",
    "        next_a, max_q_next_s_a = max_dict(Q[next_s])\n",
    "        # TODO: Implement the Q-Learning update formula from the pseudo code.\n",
    "        Q[s][a] = Q[s][a] + ALPHA*(r + GAMMA*max_q_next_s_a - Q[s][a])\n",
    "        biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "        # Next state becomes current state.\n",
    "        s = next_s\n",
    "\n",
    "    deltas.append(biggest_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "Now we want to evaluate the learning performance of our Q-learning agent.\n",
    "First, we take a look at the plot of the biggest value changes for each episodes. These values should approach zero over time as our estimate of Q converges towards the real values.\n",
    "\n",
    "After that we use our action-value dictionary to determine the value of each state and the policy which is the greedy action in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Values:\n",
      "------------------------------\n",
      "-0.01|     | 0.17|-0.04|-0.04|\n",
      "------------------------------\n",
      " 0.02| 0.69| 0.77| 0.26|-0.03|\n",
      "------------------------------\n",
      " 0.05|     | 1.00|     |     |\n",
      "------------------------------\n",
      "     | 1.00| 0.80| 0.62| 0.46|\n",
      "\n",
      "Policy:\n",
      "------------------------------\n",
      "  L  |     |  D  |  D  |  R  |\n",
      "------------------------------\n",
      "  R  |  D  |  D  |  L  |  L  |\n",
      "------------------------------\n",
      "  R  |     |  L  |     |     |\n",
      "------------------------------\n",
      "     |  U  |  L  |  L  |  L  |\n",
      "\n",
      "State Visits:\n",
      "Total states visited:  46526\n",
      "------------------------------\n",
      " 0.00|     | 0.00| 0.00| 0.00|\n",
      "------------------------------\n",
      " 0.00| 0.00| 0.00| 0.00| 0.00|\n",
      "------------------------------\n",
      " 0.00|     | 0.02|     |     |\n",
      "------------------------------\n",
      "     | 0.22| 0.23| 0.26| 0.27|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the biggest value change in each episode.\n",
    "plt.plot(deltas)\n",
    "plt.show()\n",
    "\n",
    "# Determine the policy from Q and find the value of each state which corresponds to the maximum Q-value.\n",
    "policy = {}\n",
    "V = {}\n",
    "for row in range(grid.height):\n",
    "    for col in range(grid.width):\n",
    "        # Determine the greedy action in each state.\n",
    "        a, max_q = max_dict(Q[(row, col)])\n",
    "        policy[(row, col)] = a\n",
    "        # Get the value V for each state.\n",
    "        V[(row, col)] = max_q\n",
    "\n",
    "print(\"State Values:\")\n",
    "grid.print_state_values(V)\n",
    "print(\"Policy:\")\n",
    "grid.print_policy(policy)\n",
    "print(\"State Visits:\")\n",
    "grid.print_state_visits(state_visits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Upper Confidence Bound (UCB)\n",
    "<hr>\n",
    "\n",
    "**TO DO (Task 2):** Complete the `act_ucb` function to act according to the upper confidence bound. Then copy and adapt the training loop from above. Evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_ucb(Qs, t, Ns, c=0.1):\n",
    "    '''Selects an UpperConfidenceBound action given the action-values for a state, \n",
    "    the number of times a state has been visited and the number of times every action has been taken from\n",
    "    the current state.'''\n",
    "    Q_ucb = {}\n",
    "    for key, val in Qs.items():\n",
    "        Q_ucb[key] = val + c*np.sqrt(np.log10(t)/Ns[key]) \n",
    "    a, _ = max_dict(Q_ucb)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training episodes\n",
    "EPISODES = 10000\n",
    "# Discount Factor\n",
    "GAMMA = 0.9\n",
    "# Learning Rate\n",
    "ALPHA = 0.05\n",
    "# UCB Weight\n",
    "C = 50.0\n",
    "# Action space (Up, Down, Left, Right)\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 1000\n",
      "Episode: 2000\n",
      "Episode: 3000\n",
      "Episode: 4000\n",
      "Episode: 5000\n",
      "Episode: 6000\n",
      "Episode: 7000\n",
      "Episode: 8000\n",
      "Episode: 9000\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary for the action-value function Q(s,a)\n",
    "Q = {}\n",
    "# Initialize an empty dictionary for the number of times action a has been chosen in state s.\n",
    "action_visits = {}\n",
    "# Initialize an empty dictionary for the number of times state s has been visited.\n",
    "state_visits = {}\n",
    "\n",
    "# For each state corresponding to each field in the environment, create a new dictionary inside the dictionaries.\n",
    "for row in range(grid.height):\n",
    "    for col in range(grid.width):\n",
    "        Q[(row, col)] = {}\n",
    "        action_visits[(row, col)] = {}\n",
    "        state_visits[(row, col)] = 1\n",
    "        # For each action in each state create a new entry in the dictonary setting its estimated value to 0.\n",
    "        for a in ALL_POSSIBLE_ACTIONS:\n",
    "            Q[(row, col)][a] = 0\n",
    "            action_visits[(row, col)][a] = 1\n",
    "            \n",
    "# Keep track of the maximum value changes during each episode so we can print a learning curve after the training       \n",
    "deltas = []\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "# Play EPISODES number of episodes in the environment while learning after each step.\n",
    "for e in range(EPISODES):\n",
    "    # Every 1000 steps print the current episode number and epsilon\n",
    "    if e % 1000 == 0:\n",
    "        print(\"Episode: {}\".format(e))\n",
    "\n",
    "    # Set the starting state\n",
    "    grid.reset()\n",
    "    s = grid.get_current_state()\n",
    "\n",
    "    biggest_change = 0\n",
    "    while not grid.is_state_terminal():\n",
    "        # Choose an action according to UCB.\n",
    "        a = act_ucb(Q[s], state_visits[s], action_visits[s], c=C)\n",
    "        r = grid.move(a)\n",
    "        next_s = grid.get_current_state()\n",
    "        \n",
    "        # Update the state and action visits number.\n",
    "        state_visits[s] += 1\n",
    "        action_visits[s][a] += 1\n",
    "\n",
    "        # Update Q(s,a)\n",
    "        old_qsa = Q[s][a]\n",
    "        next_a, max_q_next_s_a = max_dict(Q[next_s])\n",
    "        # TODO: Implement the Q-Learning update formula from the pseudo code.\n",
    "        Q[s][a] = Q[s][a] + ALPHA*(r + GAMMA*max_q_next_s_a - Q[s][a])\n",
    "        biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "        # Next state becomes current state.\n",
    "        s = next_s\n",
    "\n",
    "    deltas.append(biggest_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Values:\n",
      "------------------------------\n",
      " 0.62|     | 0.62| 0.46| 0.31|\n",
      "------------------------------\n",
      " 0.80| 1.00| 0.80| 0.62| 0.46|\n",
      "------------------------------\n",
      " 1.00|     | 1.00|     |     |\n",
      "------------------------------\n",
      "     | 1.00| 0.80| 0.62| 0.46|\n",
      "\n",
      "Policy:\n",
      "------------------------------\n",
      "  D  |     |  D  |  L  |  L  |\n",
      "------------------------------\n",
      "  R  |  D  |  D  |  L  |  L  |\n",
      "------------------------------\n",
      "  R  |     |  L  |     |     |\n",
      "------------------------------\n",
      "     |  U  |  U  |  L  |  L  |\n",
      "\n",
      "State Visits:\n",
      "Total states visited:  139029\n",
      "------------------------------\n",
      " 0.01|     | 0.02| 0.02| 0.01|\n",
      "------------------------------\n",
      " 0.01| 0.01| 0.03| 0.02| 0.01|\n",
      "------------------------------\n",
      " 0.00|     | 0.07|     |     |\n",
      "------------------------------\n",
      "     | 0.09| 0.15| 0.26| 0.28|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the biggest value change in each episode.\n",
    "plt.plot(deltas)\n",
    "plt.show()\n",
    "\n",
    "# Determine the policy from Q and find the value of each state which corresponds to the maximum Q-value.\n",
    "policy = {}\n",
    "V = {}\n",
    "for row in range(grid.height):\n",
    "    for col in range(grid.width):\n",
    "        # Determine the greedy action in each state.\n",
    "        a, max_q = max_dict(Q[(row, col)])\n",
    "        policy[(row, col)] = a\n",
    "        # Get the value V for each state.\n",
    "        V[(row, col)] = max_q\n",
    "\n",
    "print(\"State Values:\")\n",
    "grid.print_state_values(V)\n",
    "print(\"Policy:\")\n",
    "grid.print_policy(policy)\n",
    "print(\"State Visits:\")\n",
    "grid.print_state_visits(state_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
