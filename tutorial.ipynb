{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the system\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# from pyimagesearch.resnet import ResNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Dataset\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the images have been loaded correctly\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "import matplotlib.image as mpimg\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "pic_index = 100\n",
    "train_cat_fnames = os.listdir( train_cats_dir )\n",
    "train_dog_fnames = os.listdir( train_dogs_dir )\n",
    "\n",
    "\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
    "                for fname in train_cat_fnames[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
    "                for fname in train_dog_fnames[ pic_index-8:pic_index]\n",
    "               ]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VGG16 ###\n",
    "\n",
    "# Step 1: Image Augmentation\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Training and Validation Sets\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir,  batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Loading the Base Model\n",
    "    # We will be using only the basic models, with changes made only to the final layer. \n",
    "    # This is because this is just a binary classification problem while these models \n",
    "    # are built to handle up to 1000 classes.\n",
    "\n",
    "\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')\n",
    "\n",
    "\n",
    "# Since we donâ€™t have to train all the layers, we make them non_trainable:\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile and Fit\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgghist = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inception ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Augmentation\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Training and Validation Generators\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (150, 150))\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, batch_size = 20, class_mode = 'binary', target_size = (150, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Loading the Base Model\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile and Fit\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform the following operations:\n",
    "\n",
    "    # Flatten the output of our base model to 1 dimension\n",
    "    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "    # This time, we will go with a dropout rate of 0.2\n",
    "    # Add a final Fully Connected Sigmoid Layer\n",
    "    # We will again use RMSProp, though you can try out the Adam Optimiser too\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "inc_history = model.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ResNet50 ###\n",
    "\n",
    "# Step 1: Data Augmentation and Generators\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import the base model\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we are using only the basic ResNet model, \n",
    "# so we will keep the layers frozen and only modify the last layer:\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build and Compile the Model\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "base_model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "base_model.compile(optimizer = tf.keras.optimizers.SGD(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Fitting the model\n",
    "\n",
    "resnet_history = base_model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EfficientNet ###\n",
    "\n",
    "# Installing EfficientNet:\n",
    "# %pip install -U efficientnet\n",
    "\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "\n",
    "# Step 1: Image Augmentation\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Loading the Base Model\n",
    "\n",
    "base_model = efn.EfficientNetB7(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, let us freeze the layers:\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the model\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "model_final = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile and Fit\n",
    "\n",
    "model_final.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We finally fit the model on our data:\n",
    "\n",
    "eff_history = model_final.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
