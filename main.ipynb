{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Use Cross-validation?\n",
    "    trainiere 5 oder 10 modelle mit verschiedenen validation datasets und nehme den durchschnitsswert um die Parameter anzupassen. Im Anschluss wird ein neues modell mit den neuen Parametern trainiert (es gibt kein validation dataset, also alle daten fürs Training verwenden) und dieses Modell wird dann mit den test dataset kontrolliert. -> Foliensatz 4\n",
    "\n",
    "--Parallel computation?\n",
    "\n",
    "--Batch size\n",
    "    how many input datasets are computed in parallel\n",
    "    weights werden pro batch geupdatet und nicht auf den ganzen datensatz\n",
    "    larger batch size -> little bit less noise\n",
    "                      -> training gets slower\n",
    "                      -> kann den Datensatz besser darstellen und wird daher besser optimiert\n",
    "    smaller batch size -> cannot represent the entire dataset good enough \n",
    "                       -> schnelleres Training\n",
    "                       -> die optimierung der kleinen Batches gehen eventuell in verschiedene Richtungen\n",
    "\n",
    "--Optimizer\n",
    "    -Adam?\n",
    "\n",
    "--Shuffel dataset\n",
    "    Shuffel dataset and divide it into the number of folds (so each fold can represent the entire dataset)\n",
    "\n",
    "--Traininf-loss\n",
    "    = Trained neural network + error on known data\n",
    "\n",
    "--Data Augnentation\n",
    "    hintergrund von Bildern entfernen bzw durch weißen Hintergrund ersetzten damit es einfacher für das NN ist zum trainieren\n",
    "    change image brigthtness, rotation, spiegeln -> to get more picutes\n",
    "\n",
    "--Dropout\n",
    "    switch off a defined percentage of randomly chosen units during training\n",
    "\n",
    "--Normalization\n",
    "    normalisiert die Farbwerte so dass es mehr kontrast in den Bildern gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
