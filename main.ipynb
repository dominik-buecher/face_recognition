{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Use Cross-validation?\n",
    "    trainiere 5 oder 10 modelle mit verschiedenen validation datasets und nehme den durchschnitsswert um die Parameter anzupassen. Im Anschluss wird ein neues modell mit den neuen Parametern trainiert (es gibt kein validation dataset, also alle daten fürs Training verwenden) und dieses Modell wird dann mit den test dataset kontrolliert. -> Foliensatz 4\n",
    "\n",
    "--Parallel computation?\n",
    "\n",
    "--Batch size\n",
    "    how many input datasets are computed in parallel\n",
    "    weights werden pro batch geupdatet und nicht auf den ganzen datensatz\n",
    "    larger batch size -> little bit less noise\n",
    "                      -> training gets slower\n",
    "                      -> kann den Datensatz besser darstellen und wird daher besser optimiert\n",
    "    smaller batch size -> cannot represent the entire dataset good enough \n",
    "                       -> schnelleres Training\n",
    "                       -> die optimierung der kleinen Batches gehen eventuell in verschiedene Richtungen\n",
    "\n",
    "--Optimizer\n",
    "    -Adam?\n",
    "\n",
    "--Shuffel dataset\n",
    "    Shuffel dataset and divide it into the number of folds (so each fold can represent the entire dataset)\n",
    "\n",
    "--Traininf-loss\n",
    "    = Trained neural network + error on known data\n",
    "\n",
    "--Data Augnentation\n",
    "    hintergrund von Bildern entfernen bzw durch weißen Hintergrund ersetzten damit es einfacher für das NN ist zum trainieren\n",
    "    change image brigthtness, rotation, spiegeln -> to get more picutes\n",
    "\n",
    "--Dropout\n",
    "    switch off a defined percentage of randomly chosen units during training\n",
    "\n",
    "--Normalization\n",
    "    normalisiert die Farbwerte so dass es mehr kontrast in den Bildern gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch-Size: Think of a batch as a for-loop iterating over one or more samples and making predictions. At the end of the batch, the    predictions are compared to the expected output variables and an error is calculated. From this error, the update algorithm is used to improve the model, e.g. move down along the error gradient.\n",
    "-What if the dataset does not divide evenly by the batch size?\n",
    "    --> This can and does happen often when training a model. It simply means that the final batch has fewer samples than the other batches.\n",
    "\n",
    "Epochen: The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
    "\n",
    "One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. For example, as above, an epoch that has one batch is called the batch gradient descent learning algorithm.\n",
    "\n",
    "You can think of a for-loop over the number of epochs where each loop proceeds over the training dataset. Within this for-loop is another nested for-loop that iterates over each batch of samples, where one batch has the specified “batch size” number of samples.\n",
    "\n",
    "The batch size is a number of samples processed before the model is updated.\n",
    "\n",
    "The number of epochs is the number of complete passes through the training dataset.\n",
    "\n",
    "\n",
    "Steps_per_epoch: Total number of steps (batches of samples)\n",
    "            before declaring one epoch finished and starting the\n",
    "            next epoch. When training with input tensors such as\n",
    "            TensorFlow data tensors, the default `None` is equal to\n",
    "            the number of samples in your dataset divided by\n",
    "            the batch size, or 1 if that cannot be determined. If x is a\n",
    "            `tf.data` dataset, and 'steps_per_epoch'\n",
    "            is None, the epoch will run until the input dataset is exhausted.\n",
    "            When passing an infinitely repeating dataset, you must specify the\n",
    "            `steps_per_epoch` argument.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
